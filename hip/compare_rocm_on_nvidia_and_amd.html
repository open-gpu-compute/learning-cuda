

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Porting CUDA C++ code &mdash; Tutorials 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Installing PyTorch on AMD with ROCm" href="installing_pytorch.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Tutorials
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">CUDA Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cuda/introduction_to_cuda.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_model.html">Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_interface.html">Programming Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines.html">Hardware Implementations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines.html#performance-guidlines">Performance Guidlines</a></li>
</ul>
<p class="caption"><span class="caption-text">HIP Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_guide.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing_pytorch.html">Installing PyTorch on AMD with ROCm</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Porting  CUDA C++ code</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#hipify-clang"><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#hipify-perl"><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#running-hip-code-on-nvidia">Running HIP code on NVIDIA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#install-rocm-stack-on-nvidia">Install ROCM stack on NVIDIA</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compiling-hip-code">Compiling HIP Code.</a></li>
</ul>
</li>
<<<<<<< HEAD
<li class="toctree-l1"><a class="reference internal" href="#benchmarks">Benchmarks</a></li>
=======
>>>>>>> 6e14eee67140eb9233c8afb7aa4b484f7969de75
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Tutorials</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Porting  CUDA C++ code</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hip/compare_rocm_on_nvidia_and_amd.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="porting-cuda-c-code">
<h1>Porting  CUDA C++ code<a class="headerlink" href="#porting-cuda-c-code" title="Permalink to this headline">¶</a></h1>
<p>ROCm provides 2 tools to convert CUDA C++ code to HIP C++ code, namely <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> and <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code>.</p>
<div class="section" id="hipify-clang">
<h2><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code><a class="headerlink" href="#hipify-clang" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> is a clang-based tool for translation CUDA sources into HIP sources.
It translates CUDA source into an abstract syntax tree, which is being traversed by transformation matchers.
After applying all the matchers, the output HIP source is produced.</p>
<ol class="simple">
<li><p>It is a translator; thus, any even very complicated constructs will be parsed successfully, or an error will be reported.</p></li>
<li><p>It supports clang options like <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-i-dir"><code class="docutils literal notranslate"><span class="pre">-I</span></code></a>, <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-d-macro"><code class="docutils literal notranslate"><span class="pre">-D</span></code></a>, <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-cuda-path"><code class="docutils literal notranslate"><span class="pre">--cuda-path</span></code></a>, etc.</p></li>
<li><p>Seamless support of new CUDA versions as it is clang’s responsibility.</p></li>
<li><p>Ease in support.</p></li>
</ol>
<p>For example to translate the file at <code class="docutils literal notranslate"><span class="pre">../cuda/src/vector_add.cu</span></code>, type</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hipify-clang vector_add.cu --cuda-path<span class="o">=</span>/usr/local/cuda-11.0 -- -std<span class="o">=</span>c++17
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">test-hipify</span></code> command is used to check if that a particular CUDA code can be converted to HIP.</p>
</div>
<div class="section" id="hipify-perl">
<h2><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code><a class="headerlink" href="#hipify-perl" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> is autogenerated perl-based script which heavily uses regular expressions.</p>
<ol class="simple">
<li><p>Ease in use.</p></li>
<li><p>It doesn’t check the input source CUDA code for correctness.</p></li>
<li><p>It doesn’t have dependencies on 3rd party tools, including CUDA.</p></li>
</ol>
<p>For example to translate the file at <code class="docutils literal notranslate"><span class="pre">../cuda/src/vector_add.cu</span></code>, use</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hipify-perl vector_add.cu &gt; vector_add.cu.hip
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-hip-code-on-nvidia">
<h1>Running HIP code on NVIDIA<a class="headerlink" href="#running-hip-code-on-nvidia" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-rocm-stack-on-nvidia">
<h2>Install ROCM stack on NVIDIA<a class="headerlink" href="#install-rocm-stack-on-nvidia" title="Permalink to this headline">¶</a></h2>
<p>Installing all the dependencies of ROCM and ROCM itself on NVIDIA is a tedious task. To build ROCm on docker would be much more easier and streamlined.</p>
<ol class="simple">
<li><p>Download the docker file from here https://raw.githubusercontent.com/open-gpu-compute/builds/main/Rocm_Dockerfile</p></li>
<li><p>Build the docker image using <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">docker</span> <span class="pre">build</span> <span class="pre">.</span></code> This should complete with a message “Successfully built &lt;image_id&gt;”</p></li>
<li><p>Start a docker container using the new image:
<code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">docker</span> <span class="pre">run</span> <span class="pre">-it</span> <span class="pre">-v</span> <span class="pre">$HOME:/data</span> <span class="pre">--privileged</span> <span class="pre">--rm</span> <span class="pre">--device=/dev/kfd</span> <span class="pre">--device=/dev/dri</span> <span class="pre">--group-add</span> <span class="pre">video</span> <span class="pre">&lt;image_id&gt;</span></code>
Note: This will mount your host home directory on <code class="docutils literal notranslate"><span class="pre">/data</span></code> in the container.
This will install all the ROCM packages along with <code class="docutils literal notranslate"><span class="pre">hipcc</span></code> and <code class="docutils literal notranslate"><span class="pre">hipify</span></code> on NVIDIA Gpu</p></li>
</ol>
</div>
<div class="section" id="compiling-hip-code">
<h2>Compiling HIP Code.<a class="headerlink" href="#compiling-hip-code" title="Permalink to this headline">¶</a></h2>
<p>HIP C++ code can be compiled with either with NVidia GPU or with AMD. Once ROCM software stack is installed on NVIDIA, HIP code can be compiled using similar command on both NVidia and AMD.</p>
</div>
</div>
<<<<<<< HEAD
<div class="section" id="benchmarks">
<h1>Benchmarks<a class="headerlink" href="#benchmarks" title="Permalink to this headline">¶</a></h1>
<p>Following table comapares different GPU operations on NVIDIA GPU with CUDA, NVIDIA GPU with ROCM and AMD GPU with ROCM
|                                                             | NVIDIA with CUDA | NVIDIA with ROCm  | AMD with ROCm     |
|————————————————————-|——————|——————-|——————-|
|                                                             |                  |                   |                   |
| Vector Addition (n=100000)                                  | 984 microseconds | 1001 microseconds | 1011 microseconds |
| Matrix Multiplication w/out shared memory           n=10000 | 458 microseconds | 598 microseconds  | 616 microseconds  |
| Matrix Multiplication with shared memory          n=10000   | 7 microseconds   | 8 microseconds    | 8 microseconds    |</p>
<p>As we see shared memory plays a huge difference when it comes to matrix multipliccation.</p>
<p>Disclaimer : GPUs used in benchmarking are of different compute capabilities.</p>
</div>
=======
>>>>>>> 6e14eee67140eb9233c8afb7aa4b484f7969de75


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="installing_pytorch.html" class="btn btn-neutral float-left" title="Installing PyTorch on AMD with ROCm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Yash Jain

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>