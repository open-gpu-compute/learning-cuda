

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Programming Guide &mdash; Tutorials 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Installing PyTorch on AMD with ROCm" href="installing_pytorch.html" />
    <link rel="prev" title="Introduction" href="introduction.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Tutorials
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">CUDA Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cuda/introduction_to_cuda.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_model.html">Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_interface.html">Programming Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines.html">Hardware Implementations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines.html#performance-guidlines">Performance Guidlines</a></li>
</ul>
<p class="caption"><span class="caption-text">HIP Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Programming Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#coding-tutorial">Coding Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mapped-memory">Mapped Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="#matrix-multiplication-using-shared-memory-in-hip">Matrix Multiplication Using Shared Memory in HIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stream">Stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="#events">Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multi-device-system">Multi-Device System</a></li>
<li class="toctree-l2"><a class="reference internal" href="#peer-to-peer-memory-access">Peer-to-Peer Memory Access</a></li>
<li class="toctree-l2"><a class="reference internal" href="#porting-cuda-c-code">Porting  CUDA C++ code</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hipify-clang"><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hipify-perl"><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installing_pytorch.html">Installing PyTorch on AMD with ROCm</a></li>
<li class="toctree-l1"><a class="reference internal" href="compare_rocm_on_nvidia_and_amd.html">Porting  CUDA C++ code</a></li>
<li class="toctree-l1"><a class="reference internal" href="compare_rocm_on_nvidia_and_amd.html#running-hip-code-on-nvidia">Running HIP code on NVIDIA</a></li>
<<<<<<< HEAD
<li class="toctree-l1"><a class="reference internal" href="compare_rocm_on_nvidia_and_amd.html#benchmarks">Benchmarks</a></li>
=======
>>>>>>> 6e14eee67140eb9233c8afb7aa4b484f7969de75
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Tutorials</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Programming Guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hip/programming_guide.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="programming-guide">
<h1>Programming Guide<a class="headerlink" href="#programming-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="coding-tutorial">
<h2>Coding Tutorial<a class="headerlink" href="#coding-tutorial" title="Permalink to this headline">¶</a></h2>
<p>Following tutorial goes through rotates a string by 1 ASCII character. You can find the full code at <code class="docutils literal notranslate"><span class="pre">src/string.cpp</span></code></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="n">helloworld</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span> <span class="n">in</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">out</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">num</span> <span class="o">=</span> <span class="n">hipThreadIdx_x</span> <span class="o">+</span> <span class="n">hipBlockDim_x</span> <span class="o">*</span> <span class="n">hipBlockIdx_x</span><span class="p">;</span>
	<span class="n">out</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">in</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="n">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>

    <span class="n">hipDeviceProp_t</span> <span class="n">devProp</span><span class="p">;</span>
    <span class="n">hipGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">devProp</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; System minor &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">devProp</span><span class="p">.</span><span class="n">minor</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; System major &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">devProp</span><span class="p">.</span><span class="n">major</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; agent prop name &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">devProp</span><span class="p">.</span><span class="n">name</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

    <span class="c1">//Initial input,output for the host and create memory objects for the kernel</span>
    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">input</span> <span class="o">=</span> <span class="s">&quot;GdkknVnqkc&quot;</span><span class="p">;</span>
    <span class="kt">size_t</span> <span class="n">strlength</span> <span class="o">=</span> <span class="n">strlen</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;input string:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">input</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>

    <span class="kt">char</span><span class="o">*</span> <span class="n">inputBuffer</span><span class="p">;</span>
    <span class="kt">char</span><span class="o">*</span> <span class="n">outputBuffer</span><span class="p">;</span>
    <span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">inputBuffer</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">));</span>
    <span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">outputBuffer</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">));</span>

    <span class="n">hipMemcpy</span><span class="p">(</span><span class="n">inputBuffer</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">),</span> <span class="n">hipMemcpyHostToDevice</span><span class="p">);</span>

    <span class="n">hipLaunchKernelGGL</span><span class="p">(</span><span class="n">helloworld</span><span class="p">,</span><span class="n">dim3</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">dim3</span><span class="p">(</span><span class="n">strlength</span><span class="p">),</span>
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span><span class="n">inputBuffer</span> <span class="p">,</span><span class="n">outputBuffer</span> <span class="p">);</span>

    <span class="n">hipMemcpy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">outputBuffer</span><span class="p">,(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">),</span> <span class="n">hipMemcpyDeviceToHost</span><span class="p">);</span>

    <span class="n">hipFree</span><span class="p">(</span><span class="n">inputBuffer</span><span class="p">);</span>
    <span class="n">hipFree</span><span class="p">(</span><span class="n">outputBuffer</span><span class="p">);</span>

    <span class="n">output</span><span class="p">[</span><span class="n">strlength</span><span class="p">]</span> <span class="o">=</span> <span class="sc">&#39;\0&#39;</span><span class="p">;</span>	<span class="c1">//Add the terminal character to the end of output.</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">output string:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">output</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>

    <span class="n">free</span><span class="p">(</span><span class="n">output</span><span class="p">);</span>

    <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;Passed!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>We will now go through the code line by line,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;hip/hip_runtime.h&gt;</span><span class="cp"></span>
</pre></div>
</div>
<p>Include headers for HIP runtime libraries</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="n">helloworld</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span> <span class="n">in</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">out</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">num</span> <span class="o">=</span> <span class="n">hipThreadIdx_x</span> <span class="o">+</span> <span class="n">hipBlockDim_x</span> <span class="o">*</span> <span class="n">hipBlockIdx_x</span><span class="p">;</span>
	<span class="n">out</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">in</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Supported <code class="docutils literal notranslate"><span class="pre">__global__</span></code> functions are executed on the device and called (“launched”) from the host.
HIP <code class="docutils literal notranslate"><span class="pre">__global__</span></code> functions must have a void return type.
Apart from <code class="docutils literal notranslate"><span class="pre">__global__</span></code> functions, there are two more types of functions in HIP:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__device__</span></code> :Supported <code class="docutils literal notranslate"><span class="pre">__device__</span></code> functions are executed on the device, called from the device only.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__host__</span></code>: Supported <code class="docutils literal notranslate"><span class="pre">__host__</span></code> functions are executed on the host and called from the host
<code class="docutils literal notranslate"><span class="pre">__host__</span></code> can combine with <code class="docutils literal notranslate"><span class="pre">__device__</span></code>, in which case the function compiles for both the host and device. These functions cannot use the HIP grid coordinate function.</p></li>
</ul>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipDeviceProp_t</span> <span class="n">devProp</span><span class="p">;</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hipDeviceProp_t</span></code> is a struct use to store device properties similar to CUdevprop</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">devProp</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hipGetDeviceProperties</span></code> returns properties for a selected device.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">inputBuffer</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">));</span>
<span class="n">hipMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">outputBuffer</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">));</span>
<span class="n">hipMemcpy</span><span class="p">(</span><span class="n">inputBuffer</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="p">(</span><span class="n">strlength</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">char</span><span class="p">),</span> <span class="n">hipMemcpyHostToDevice</span><span class="p">);</span>
</pre></div>
</div>
<p>The runtime provides built-in functions to allocate, deallocate and copy device memory. It also provides functions to transfer data between the device and host memory. The device memory can be allocated as linear memory . Linear memory uses a single unified address space, which allows separately allocated entities to address each other via pointers. Linear memory is allocated using <code class="docutils literal notranslate"><span class="pre">hipMalloc()</span></code> and freed using <code class="docutils literal notranslate"><span class="pre">hipFree()</span></code>, and data transfer between host memory and device memory is done using <code class="docutils literal notranslate"><span class="pre">hipMemcpy()</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipLaunchKernelGGL</span><span class="p">(</span><span class="n">helloworld</span><span class="p">,</span><span class="n">dim3</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">dim3</span><span class="p">(</span><span class="n">strlength</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span><span class="n">inputBuffer</span> <span class="p">,</span><span class="n">outputBuffer</span> <span class="p">);</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">__global__</span></code> functions are often referred to as kernels, and calling one is termed launching the kernel. These functions require the caller to specify an “execution configuration” that includes the grid and block dimensions. The execution configuration can also include other information for the launch, such as the amount of additional shared memory to allocate and the stream where the kernel should execute. HIP introduces a standard C++ calling convention to pass the execution configuration to the kernel in addition to the Cuda <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;</span> <span class="pre">&gt;&gt;&gt;</span></code> syntax. In HIP,
Kernels launch with either <code class="docutils literal notranslate"><span class="pre">&lt;&lt;&lt;</span> <span class="pre">&gt;&gt;&gt;</span></code> syntax or the “hipLaunchKernel” function
The first five parameters to hipLaunchKernel are the following:</p>
<ul class="simple">
<li><p>symbol kernelName: the name of the kernel to launch. To support template kernels which contains “,” use the HIP_KERNEL_NAME macro. The hipify tools insert this automatically.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">gridDim</span></code>: 3D-grid dimensions specifying the number of blocks to launch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dim3</span> <span class="pre">blockDim</span></code>: 3D-block dimensions specifying the number of threads in each block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">size_t</span> <span class="pre">dynamicShared</span></code>: amount of additional shared memory to allocate when launching the kernel (see shared)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hipStream_t</span></code>: stream where the kernel should execute.
<code class="docutils literal notranslate"><span class="pre">dim3</span></code> is a three-dimensional integer vector type commonly used to specify grid and group dimensions. Unspecified dimensions are initialized to 1.</p></li>
</ul>
</div>
<div class="section" id="mapped-memory">
<h2>Mapped Memory<a class="headerlink" href="#mapped-memory" title="Permalink to this headline">¶</a></h2>
<p>A block of page-locked host memory can also be mapped into the address space of the device by passing flag<code class="docutils literal notranslate"><span class="pre">hipHostAllocMapped</span></code> to <code class="docutils literal notranslate"><span class="pre">hipHostAlloc()</span></code> or by passing flag <code class="docutils literal notranslate"><span class="pre">hipHostRegisterMapped</span></code> to <code class="docutils literal notranslate"><span class="pre">hipHostRegister()</span></code>. Such a block has therefore in general two addresses: one in host memory that is returned by <code class="docutils literal notranslate"><span class="pre">hipHostMalloc()</span></code> or <code class="docutils literal notranslate"><span class="pre">malloc()</span></code>, and one in device memory that can be retrieved using <code class="docutils literal notranslate"><span class="pre">hipHostGetDevicePointer()</span></code> and then used to access the block from within a kernel.</p>
</div>
<div class="section" id="matrix-multiplication-using-shared-memory-in-hip">
<h2>Matrix Multiplication Using Shared Memory in HIP<a class="headerlink" href="#matrix-multiplication-using-shared-memory-in-hip" title="Permalink to this headline">¶</a></h2>
<p>Below contains the code for matrix multiplication in HIP using shared memory. Full code can be found at <code class="docutils literal notranslate"><span class="pre">src/mat_mul.src</span></code></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span> <span class="n">__global__</span> <span class="kt">void</span>  <span class="n">MatMulKernelSharedMemory</span><span class="p">(</span><span class="n">Matrix</span> <span class="n">A</span><span class="p">,</span> <span class="n">Matrix</span> <span class="n">B</span><span class="p">,</span> <span class="n">Matrix</span> <span class="n">C</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// Block row and column</span>
    <span class="kt">int</span> <span class="n">blockRow</span> <span class="o">=</span> <span class="n">hipBlockIdx_y</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">blockCol</span> <span class="o">=</span> <span class="n">hipBlockIdx_x</span><span class="p">;</span>

    <span class="c1">// Each thread block computes one sub-matrix Csub of C</span>
    <span class="n">Matrix</span> <span class="n">Csub</span> <span class="o">=</span> <span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">blockRow</span><span class="p">,</span> <span class="n">blockCol</span><span class="p">);</span>

    <span class="c1">// Each thread computes one element of Csub</span>
    <span class="c1">// by accumulating results into Cvalue</span>
    <span class="kt">float</span> <span class="n">Cvalue</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="c1">// Thread row and column within Csub</span>
    <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">hipThreadIdx_y</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">hipThreadIdx_x</span><span class="p">;</span>

    <span class="c1">// Loop over all the sub-matrices of A and B that are</span>
    <span class="c1">// required to compute Csub</span>
    <span class="c1">// Multiply each pair of sub-matrices together</span>
    <span class="c1">// and accumulate the results</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">width</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span> <span class="o">++</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>

        <span class="c1">// Get sub-matrix Asub of A</span>
        <span class="n">Matrix</span> <span class="n">Asub</span> <span class="o">=</span> <span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">blockRow</span><span class="p">,</span> <span class="n">m</span><span class="p">);</span>

        <span class="c1">// Get sub-matrix Bsub of B</span>
        <span class="n">Matrix</span> <span class="n">Bsub</span> <span class="o">=</span> <span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">blockCol</span><span class="p">);</span>

        <span class="c1">// Shared memory used to store Asub and Bsub respectively</span>
        <span class="n">__shared__</span> <span class="kt">float</span> <span class="n">As</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span>
        <span class="n">__shared__</span> <span class="kt">float</span> <span class="n">Bs</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span>

        <span class="c1">// Load Asub and Bsub from device memory to shared memory</span>
        <span class="c1">// Each thread loads one element of each sub-matrix</span>
        <span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">GetElement</span><span class="p">(</span><span class="n">Asub</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">);</span>
        <span class="n">Bs</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">GetElement</span><span class="p">(</span><span class="n">Bsub</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">);</span>

        <span class="c1">// Synchronize to make sure the sub-matrices are loaded</span>
        <span class="c1">// before starting the computation</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
        <span class="c1">// Multiply Asub and Bsub together</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">e</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">e</span> <span class="o">&lt;</span> <span class="n">BLOCK_SIZE</span><span class="p">;</span> <span class="o">++</span><span class="n">e</span><span class="p">)</span>
            <span class="n">Cvalue</span> <span class="o">+=</span> <span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">*</span> <span class="n">Bs</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">col</span><span class="p">];</span>

        <span class="c1">// Synchronize to make sure that the preceding</span>
        <span class="c1">// computation is done before loading two new</span>
        <span class="c1">// sub-matrices of A and B in the next iteration</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">__shared__</span></code> : Shared memory is allocated using <code class="docutils literal notranslate"><span class="pre">__shared__</span></code> memory space specifier. Its is faster than global memory and reduce global memory access calls.</p>
</div>
<div class="section" id="stream">
<h2>Stream<a class="headerlink" href="#stream" title="Permalink to this headline">¶</a></h2>
<p>Streams are a sequence of commands that execute in order. There can be multiple streams executed on different kernels. If kernel launches do not specify a stream, the commands are run on default stream, known as stream 0. The following code sample creates two streams.Each of these streams is defined by the following code sample as a sequence of one memory copy from host to device and one memory copy from device to host:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipStream_t</span> <span class="n">stream</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
    <span class="n">hipStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">hostPtr</span><span class="p">;</span>
<span class="n">hipMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostPtr</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">size</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">hipMemcpyAsync</span><span class="p">(</span><span class="n">inputDevPtr</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">size</span><span class="p">,</span> <span class="n">hostPtr</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">size</span><span class="p">,</span>
                    <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span> <span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="n">hipMemcpyAsync</span><span class="p">(</span><span class="n">hostPtr</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">size</span><span class="p">,</span> <span class="n">outputDevPtr</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">size</span><span class="p">,</span>
                    <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span> <span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
    <span class="n">hipStreamDestroy</span><span class="p">(</span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize()</span></code> waits until all preceding commands in all streams of all host threads have completed. cudaStreamSynchronize()takes a stream as a parameter and waits until all preceding commands in the given stream have completed.</p>
</div>
<div class="section" id="events">
<h2>Events<a class="headerlink" href="#events" title="Permalink to this headline">¶</a></h2>
<p>The HIP runtime provides a way to monitor the device’s progress by letting the application asynchronously record events at any point in the program, and query when these events are completed.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipEvent_t</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">;</span> 
<span class="n">hipEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start</span><span class="p">);</span> 
<span class="n">hipEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stop</span><span class="p">);</span> 
</pre></div>
</div>
</div>
<div class="section" id="multi-device-system">
<h2>Multi-Device System<a class="headerlink" href="#multi-device-system" title="Permalink to this headline">¶</a></h2>
<p>Similar to CUDA, HIP support multiple devices for a host. A certain device can be selected for a certain stream.
A host thread can set the device it operates on at any time by calling <code class="docutils literal notranslate"><span class="pre">hipSetDevice()</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span> <span class="n">deviceCount</span><span class="p">;</span>
<span class="n">hipGetDeviceCount</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceCount</span><span class="p">);</span>
<span class="kt">int</span> <span class="n">device</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="n">device</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">device</span> <span class="o">&lt;</span> <span class="n">deviceCount</span><span class="p">;</span> <span class="o">++</span><span class="n">device</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">hipDeviceProp</span> <span class="n">deviceProp</span><span class="p">;</span>
    <span class="n">hipGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceProp</span><span class="p">,</span> <span class="n">device</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Device %d has compute capability %d.%d.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
           <span class="n">device</span><span class="p">,</span> <span class="n">deviceProp</span><span class="p">.</span><span class="n">major</span><span class="p">,</span> <span class="n">deviceProp</span><span class="p">.</span><span class="n">minor</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This code lets you print properties of device on the system.</p>
</div>
<div class="section" id="peer-to-peer-memory-access">
<h2>Peer-to-Peer Memory Access<a class="headerlink" href="#peer-to-peer-memory-access" title="Permalink to this headline">¶</a></h2>
<p>In a system with multiple devices, devices can address each other’s memory depending upon their compute capability.
This peer-to-peer memory access feature is supported between two devices if <code class="docutils literal notranslate"><span class="pre">hipDeviceCanAccessPeer()</span></code> returns true for these two devices.
A unified address space is used for both devices, so the same pointer can be used to address memory from both devices as shown in the code sample below</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">hipSetDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>                   <span class="c1">// Set device 0 as current</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">p0</span><span class="p">;</span>
<span class="kt">size_t</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="n">hipMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p0</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>              <span class="c1">// Allocate memory on device 0</span>
<span class="n">hipSetDevice</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>                   <span class="c1">// Set device 1 as current</span>
<span class="n">hipDeviceEnablePeerAccess</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>   <span class="c1">// Enable peer-to-peer access</span>
                                    <span class="c1">// with device 0</span>
</pre></div>
</div>
</div>
<div class="section" id="porting-cuda-c-code">
<h2>Porting  CUDA C++ code<a class="headerlink" href="#porting-cuda-c-code" title="Permalink to this headline">¶</a></h2>
<p>ROCm provides 2 tools to convert CUDA C++ code to HIP C++ code, namely <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> and <code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code>.</p>
<div class="section" id="hipify-clang">
<h3><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code><a class="headerlink" href="#hipify-clang" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> is a clang-based tool for translation CUDA sources into HIP sources.
It translates CUDA source into an abstract syntax tree, which is being traversed by transformation matchers.
After applying all the matchers, the output HIP source is produced.</p>
<ol class="simple">
<li><p>It is a translator; thus, any even very complicated constructs will be parsed successfully, or an error will be reported.</p></li>
<li><p>It supports clang options like <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-i-dir"><code class="docutils literal notranslate"><span class="pre">-I</span></code></a>, <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-d-macro"><code class="docutils literal notranslate"><span class="pre">-D</span></code></a>, <a class="reference external" href="https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-cuda-path"><code class="docutils literal notranslate"><span class="pre">--cuda-path</span></code></a>, etc.</p></li>
<li><p>Seamless support of new CUDA versions as it is clang’s responsibility.</p></li>
<li><p>Ease in support.</p></li>
</ol>
<p>For example to translate the file at <code class="docutils literal notranslate"><span class="pre">../cuda/src/vector_add.cu</span></code>, type</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hipify-clang vector_add.cu --cuda-path<span class="o">=</span>/usr/local/cuda-11.0 -- -std<span class="o">=</span>c++17
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">test-hipify</span></code> command is used to check if that a particular CUDA code can be converted to HIP.</p>
</div>
<div class="section" id="hipify-perl">
<h3><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code><a class="headerlink" href="#hipify-perl" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">hipify-perl</span></code> is autogenerated perl-based script which heavily uses regular expressions.</p>
<ol class="simple">
<li><p>Ease in use.</p></li>
<li><p>It doesn’t check the input source CUDA code for correctness.</p></li>
<li><p>It doesn’t have dependencies on 3rd party tools, including CUDA.</p></li>
</ol>
<p>For example to translate the file at <code class="docutils literal notranslate"><span class="pre">../cuda/src/vector_add.cu</span></code>, use</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>hipify-perl vector_add.cu &gt; vector_add.cu.hip
</pre></div>
</div>
<p>HIP C++ code can be compiled with either with NVidia GPU or with AMD. On the NVIDIA CUDA platform, HIP provides header file which translate from the HIP runtime APIs to CUDA runtime APIs. So HIP code will be compiled using similar command on both NVidia and AMD.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installing_pytorch.html" class="btn btn-neutral float-right" title="Installing PyTorch on AMD with ROCm" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="introduction.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Yash Jain

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>