## Porting  CUDA C++ code
ROCm provides 2 tools to convert CUDA C++ code to HIP C++ code, namely `hipify-clang` and `hipify-perl`.

### `hipify-clang`
`hipify-clang` is a clang-based tool for translation CUDA sources into HIP sources.
It translates CUDA source into an abstract syntax tree, which is being traversed by transformation matchers.
After applying all the matchers, the output HIP source is produced.

1. It is a translator; thus, any even very complicated constructs will be parsed successfully, or an error will be reported.
2. It supports clang options like [`-I`](https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-i-dir), [`-D`](https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-d-macro), [`--cuda-path`](https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-cuda-path), etc.
3. Seamless support of new CUDA versions as it is clang's responsibility.
4. Ease in support.


For example to translate the file at `../cuda/src/vector_add.cu`, type 
```bash
hipify-clang vector_add.cu --cuda-path=/usr/local/cuda-11.0 -- -std=c++17
```
`make test-hipify` command is used to check if that a particular CUDA code can be converted to HIP.
### `hipify-perl`
`hipify-perl` is autogenerated perl-based script which heavily uses regular expressions.


1. Ease in use.
2. It doesn't check the input source CUDA code for correctness.
3. It doesn't have dependencies on 3rd party tools, including CUDA.


For example to translate the file at `../cuda/src/vector_add.cu`, use
```shell
hipify-perl vector_add.cu > vector_add.cu.hip
```



## Running HIP code on NVIDIA 

### Install ROCM stack on NVIDIA
Installing all the dependencies of ROCM and ROCM itself on NVIDIA is a tedious task. To build ROCm on docker would be much more easier and streamlined.
1. Download the docker file from here https://raw.githubusercontent.com/open-gpu-compute/builds/main/Rocm_Dockerfile
2. Build the docker image using `sudo docker build .` This should complete with a message "Successfully built <image_id>"
3.  Start a docker container using the new image:
    `sudo docker run -it -v $HOME:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video <image_id>`
    Note: This will mount your host home directory on `/data` in the container.
This will install all the ROCM packages along with `hipcc` and `hipify` on NVIDIA Gpu

### Compiling HIP Code.
HIP C++ code can be compiled with either with NVidia GPU or with AMD. Once ROCM software stack is installed on NVIDIA, HIP code can be compiled using similar command on both NVidia and AMD.

## Benchmarks
Following table comapares different GPU operations on NVIDIA GPU with CUDA, NVIDIA GPU with ROCM and AMD GPU with ROCM
|                                                             | NVIDIA with CUDA | NVIDIA with ROCm  | AMD with ROCm     |
|-------------------------------------------------------------|------------------|-------------------|-------------------|
|                                                             |                  |                   |                   |
| Vector Addition (n=100000)                                  | 984 microseconds | 1001 microseconds | 1011 microseconds |
| Matrix Multiplication w/out shared memory           n=10000 | 458 microseconds | 598 microseconds  | 616 microseconds  |
| Matrix Multiplication with shared memory          n=10000   | 7 microseconds   | 8 microseconds    | 8 microseconds    |

As we see shared memory plays a huge difference when it comes to matrix multipliccation. 

Disclaimer : GPUs used in benchmarking are of different compute capabilities.


 
