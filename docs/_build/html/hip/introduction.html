

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>What is ROCm / HCC? &mdash; Tutorials 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Programming Guide" href="programming_guide.html" />
    <link rel="prev" title="Hardware Implementations" href="../cuda/hardware_and_performance_guidlines/README.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Tutorials
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">CUDA Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cuda/introduction_to_cuda/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_model/README.html">Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/programming_interface/README.html">Programming Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines/README.html">Hardware Implementations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/hardware_and_performance_guidlines/README.html#performance-guidlines">Performance Guidlines</a></li>
</ul>
<p class="caption"><span class="caption-text">HIP Tutorial:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">What is ROCm / HCC?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#what-is-heterogeneous-computing-interface-for-portability-hip">What is Heterogeneous-Computing Interface for Portability (HIP)?</a></li>
<li class="toctree-l1"><a class="reference internal" href="#installing-hip-hcc">Installing HIP/HCC</a></li>
<li class="toctree-l1"><a class="reference internal" href="#quick-hands-on">Quick Hands-On</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_guide.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_guide.html#events">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_guide.html#multi-device-system">Multi-Device System</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Tutorials</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>What is ROCm / HCC?</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hip/introduction.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="what-is-rocm-hcc">
<h1>What is ROCm / HCC?<a class="headerlink" href="#what-is-rocm-hcc" title="Permalink to this headline">¶</a></h1>
<p>ROCm / HCC is AMD’s Single-source C++ framework for GPGPU programming. In effect: HCC is a CLang based compiler, which compiles your code in two passes. It compiles an x86 version of your code AND a GPU version of your code.
Because the same compiler processes both x86 and GPU code, it ensures that all data-structures are compatible. With AMD’s HSA project of the past, even pointers remain consistent between the codesets, allowing the programmer to easily transition between CPU and GPU code.
In effect, ROCm / HCC is AMD’s full attempt at a CUDA-like C++ environment. While OpenCL requires you to repeat yourself with any shared data-structure (in C nonetheless), HCC allows you to share pointers, classes, and structures between the CPU and GPU code.</p>
</div>
<div class="section" id="what-is-heterogeneous-computing-interface-for-portability-hip">
<h1>What is Heterogeneous-Computing Interface for Portability (HIP)?<a class="headerlink" href="#what-is-heterogeneous-computing-interface-for-portability-hip" title="Permalink to this headline">¶</a></h1>
<p>It’s a C++ dialect designed to ease conversion of Cuda applications to portable C++ code. It provides a C-style API and a C++ kernel language. The C++ interface can use templates and classes across the host/kernel boundary.
The HIPify tool automates much of the conversion work by performing a source-to-source transformation from Cuda to HIP. HIP code can run on AMD hardware (through the HCC compiler) or Nvidia hardware (through the NVCC compiler) with no performance loss compared with the original Cuda code.
Programmers familiar with other GPGPU languages will find HIP very easy to learn and use. AMD platforms implement this language using the HC dialect described above, providing similar low-level control over the machine.
Similar to CUDA, HIP transparently scales GPU’s parallelism using only three core abstractions, making the learning curve easier:</p>
<ul class="simple">
<li><p>a hierarchy of thread groups</p></li>
<li><p>shared memories</p></li>
<li><p>barrier synchronization.</p></li>
</ul>
</div>
<div class="section" id="installing-hip-hcc">
<h1>Installing HIP/HCC<a class="headerlink" href="#installing-hip-hcc" title="Permalink to this headline">¶</a></h1>
<p>https://github.com/ROCm-Developer-Tools/HIP/blob/master/INSTALL.md</p>
</div>
<div class="section" id="quick-hands-on">
<h1>Quick Hands-On<a class="headerlink" href="#quick-hands-on" title="Permalink to this headline">¶</a></h1>
<p>Below contains the code for vector addition using a CUDA kernel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="n">void</span> <span class="n">vectorAdd</span><span class="p">(</span><span class="n">const</span> <span class="nb">float</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="n">const</span> <span class="nb">float</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="nb">float</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="nb">int</span> <span class="n">numElements</span><span class="p">)</span>
<span class="p">{</span>
    <span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">numElements</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile the code and run it as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ nvcc src/vector_add.cu -o vector_add_gpu -std=c++11
$ ./vector_add_gpu
Enter number of elements in your vector:
1000000
[Vector addition of 1000000 elements]
[Copy input data from the host memory to the CUDA device]
[CUDA kernel launch with 1954 blocks of 512 threads]
Time taken by function : 62 microseconds
[Copy output data from the CUDA device to the host memory]
Done
</pre></div>
</div>
<p>The same code in HIP will be written as :</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="n">void</span> <span class="n">vectorAdd</span><span class="p">(</span><span class="n">const</span> <span class="nb">float</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="n">const</span> <span class="nb">float</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="nb">float</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="nb">int</span> <span class="n">numElements</span><span class="p">)</span>
<span class="p">{</span>
    <span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">hipThreadIdx_x</span> <span class="o">+</span> <span class="n">hipBlockDim_x</span> <span class="o">*</span> <span class="n">hipBlockIdx_x</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">numElements</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Compile the code and run it as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ hipcc src/vector_add.cpp -o vector_add_gpu -std=c++11
$ ./vector_add_gpu
Enter number of elements in your vector:
1000000
[Vector addition of 1000000 elements]
[Copy input data from the host memory to the HIP device]
[HIP kernel launch with 1954 blocks of 512 threads]
Time taken by function : 86 microseconds
[Copy output data from the HIP device to the host memory]
Done
</pre></div>
</div>
<p>If executed on GPUs with equal computation power, both CUDA and HIP take approximatively equal time to run the function.
<code class="docutils literal notranslate"><span class="pre">__global__</span></code> functions are executed on GPU and often known as Kernels.
Each thread that executes a kernel is given a <code class="docutils literal notranslate"><span class="pre">hipthreadIdx_x</span></code> that can be accessed using built-in variables.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="programming_guide.html" class="btn btn-neutral float-right" title="Programming Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../cuda/hardware_and_performance_guidlines/README.html" class="btn btn-neutral float-left" title="Hardware Implementations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Yash Jain

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>